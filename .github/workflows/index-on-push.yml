name: SmartSearch Indexing

on:
  push:
    paths:
      - 'sourcecode/**'
    branches:
      - '*'

jobs:
  run-indexing:
    runs-on: ubuntu-latest
    services:
      elasticsearch:
        image: docker.elastic.co/elasticsearch/elasticsearch:7.17.9
        ports:
          - 9200:9200
        env:
          "discovery.type": "single-node"
          "ES_JAVA_OPTS": "-Xms512m -Xmx512m"
        options: >-
          --health-cmd="curl -f http://localhost:9200/_cat/health"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=10

    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download NLTK Resources
        run: |
          mkdir -p /home/runner/nltk_data
          python -c "import nltk; nltk.download('stopwords', download_dir='/home/runner/nltk_data')"

      - name: Wait for Elasticsearch on localhost
        run: |
          for i in {1..10}; do
            if curl -s http://127.0.0.1:9200 > /dev/null; then
              echo "Elasticsearch is up on localhost:9200!"
              break
            fi
            echo "Waiting for Elasticsearch to respond..."
            sleep 5
          done

      - name: Run indexing
        env:
          NLTK_DATA: /home/runner/nltk_data
        run: |
          python codebase_search.py --index ./sourcecode
# wenn kein fehler passiert, soll er ein artefakt builden, das artefakt soll man runterladen können um nicht indexen zu müssen / akutellen stand vom index zu haben
# andere variante: yml datei berarbeiten, trigger der irgendwie lokal im docker container index ausgefügrt werden
      - name: Print Elasticsearch logs on failure
        if: failure()
        run: |
          echo "Elasticsearch container logs:"
          docker logs $(docker ps --filter "name=elasticsearch" -q)
#NEW STEPS FOR PREINDEXED IMAGE

      - name: Copy ES data to local folder
        if: success()
        run: |
          # Create a local directory
          mkdir -p es_data
          # Copy from the ephemeral ES container: /usr/share/elasticsearch/data
          docker cp $(docker ps --filter "name=elasticsearch" -q):/usr/share/elasticsearch/data es_data

      - name: Login to GHCR
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GHCR_TOKEN }}
          # ^ You must add GHCR_TOKEN in your repo's "Settings -> Secrets" (not hard-coded!)
      
      - name: Build and push preindexed ES image
        if: success()
        run: |
          # For GHCR, your image name is typically ghcr.io/<owner>/<repo>/<something>[:tag]
          IMAGE_NAME="ghcr.io/${{ github.repository_owner }}/${{ github.event.repository.name }}/smartsearch-es-preindexed:latest"

          echo "Building Docker image with preindexed data..."
          docker build -t $IMAGE_NAME -f Dockerfile.preindexed .

          echo "Pushing image $IMAGE_NAME to GHCR..."
          docker push $IMAGE_NAME